<html>

<head>
    <title>Rajan Gyawali</title>
    <link rel="stylesheet" href="others/main.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
</head>

<body>



    <!-- Content -->
    <div class="content">

        <!-- Profile Section -->
        <div class="profile-section">
            <div class="container">
                <img src="img/raj.JPG" class="profile-photo">
                <p class="profile-name">Rajan Gyawali</p>
                <div class="icons">
                    <div id="social">
                        <a href="https://www.linkedin.com/in/rajangyawali/" target="_blank"><img id="linked" src="img/linked.png" alt="Linkedin"></a>
                    </div>
                    <div id="social">
                        <a href="https://github.com/rajangyawali" target="_blank"><img id="git" src="img/git.png" alt="GitHub"></a>
                    </div>
                </div>
                <br>
                <p class="profile-detail-summary">Computer Science Doctoral Student</p>
                <p class="profile-detail-summary">Bioinformatics and Machine Learning Lab</p>
                <p class="profile-detail-summary">University of Missouri - Columbia</p>
                <p class="profile-summary">Address: Columbia, Missouri</p>
                <p class="profile-summary">Date of Birth: May 24, 1993</p>
                <p class="profile-summary">Email: rajangyawali.np@gmail.com, rgkg2@umsystem.edu</p>
                <p class="profile-summary">Phone: +1 573-639-7487</p>
                <hr>
                <p class="profile-name"><u>RESEARCH INTERESTS</u></p>
                <p class="profile-detail">Machine Learning, Deep Learning</p>
                <p class="profile-detail">Computer Vision, Bioinformatics</p>
                <hr>
                <p class="profile-name"><u>TOP SKILLS</u></p>
                <p class="profile-detail">Python, Django, REST API</p>
                <p class="profile-detail">Data Analytics and Visualizations</p>
                <p class="profile-detail">Matplotlib, Plotly, Dash</p>
                <p class="profile-detail">Numpy, Pandas</p>
                <p class="profile-detail">PostgreSQL</p>
                <p class="profile-detail">Javascript</p>
                <p class="profile-detail">Git</p>
            </div>
        </div>

        <!-- Detail Section -->
        <div class="detail-section">
            <div class="container">
                <nav class="navbar navbar-expand-lg navbar-light bg-light custom">
                    <ul class="navbar-nav ml-auto">
                        <li class="nav-item">
                            <div class="others"><a id="linkButton" href="portfolio.html">EXPERIENCE</a></div>
                        </li>
                        <li class="nav-item">
                            <div class="others"><a id="linkButton" href="https://github.com/rajangyawali/rajangyawali.github.io/blob/master/others/files/Rajan%20Gyawali%20-%20CV.pdf" target="_blank">CV</a></div>
                        </li>
                        <li class="nav-item">
                            <div class="others"><a id="linkButton" href="about.html">ABOUT ME</a></div>
                        </li>
                    </ul>
                </nav>

                <div class="card">
                    <div class="container">
                        <div class="card-title">SUMMARY</div>
                        <div class="card-body">
                            I am an engineer, currently pursuing my doctoral degree in <b>Computer Science </b> at <b> University of Missouri - Columbia</b> under the supervision of <b>Professor Dr. Jianlin Cheng</b>. I hold a Master’s degree in <b>Information and Communication Engineering</b> from the <b>Institute of Engineering, Pulchowk Campus, Tribhuvan University,</b>                            Kathmandu, Nepal. <br><br> My research interests include Machine Learning, Deep Learning, Computer Vision and Bioinformatics.
                      </div>

                    </div>
                </div>

                <div class="card">
                    <div class="container">
                        <div class="card-title">EDUCATION</div>
                        <div class="card-body">
                            <p><b>Pulchowk Campus, Tribhuvan University,</b> Lalitpur, Nepal | 2017 - 2019<br>
                                <i>MSc. Information and Communication Engineering</i> <br><small>Worked as a research student under the supervision of Dr. Dibakar Raj Pant, Pulchowk Campus.</small></p>

                            <ul>
                                <li>Percentage: <i>90.13%</i></li>
                                <li>Major Subjects: <i>Color Image Technology, Image Processing, Machine Learning & Pattern Recognition</i></li>
                                <li>Project: <b>Convolutional Neural Networks for Multiclass Face Recognition</b></li><span class="collapsible">Abstract</span>
                                <div class="collapsible-content">
                                    <p>A face recognition system based on Convolutional Neural Network is developed. The network contains five convolutional layers, each layer followed by the Rectified linear Unit and Max Pooling layer. Besides, it contains
                                        two fully connected layers and a Softmax classifier. The convolutional network extracts successively larger features in a hierarchical set of layers. A database of 13000 images of 5749 individuals is used which
                                        contains quite a higher degree of variability in expression, pose and facial details. The system can classify the images with an accuracy of 96.44%.
                                        <br><b><i>Keywords:</i></b> convolutional neural network, face recognition, classification<br>
                                        <a href="https://github.com/rajangyawali/rajangyawali.github.io/blob/master/others/files/MSc%20Project%20Report.pdf" target="_blank">Read Full Project Report</a>
                                    </p>
                                </div>
                                <li>Thesis: <b>Employee Face Recognition by Region Proposal Networks and Faster R-CNN</b></li><span class="collapsible">Abstract</span>
                                <div class="collapsible-content">
                                    <p>Face recognition is becoming popular in companies, supermarkets, hospitals etc. for security systems, human machine interaction and video surveillances. Employee face recognition is required to differentiate between
                                        employees and non-employees. Face recognition is a challenging task. The traditional machine learning algorithms like Principal Component Analysis, Support Vector Machines, etc. rely on image-based features such
                                        as edges and texture descriptors. In the recent trends, the Convolutional Neural Networks and deep learning algorithms have shown greater performance in face recognition. This thesis work uses region proposal network
                                        (RPN) to localize region of interests (faces) from the image and uses Faster R-CNN to output the region proposals’ labels and bounding box associated with them. The proposed system consists of three sections. The
                                        first section uses CNN for features extraction. From these features, the second section generates region proposals using RPN. The third section classifies these region proposals using faster R-CNN and the employee
                                        face is recognized. The recognized face has a size of 128x128. The accuracy of the model is 96.0% in recognition of employees from Chokepoint dataset. The model is further tested with recorded employees’ dataset
                                        of Nepal Telecom and shows an accuracy of 95.2%. The performance of the proposed method is evaluated on these datasets using confusion matrix. Further, visual and comprehensive evaluation using receiver operating
                                        characteristics curve for these datasets shows a clear distinction between employees and non-employees. <br><b><i>Keywords</i></b>: Employee Face Recognition, Region Proposal Networks, Convolutional Neural Network,
                                        Faster R-CNN
                                        <br>
                                        <a href="https://github.com/rajangyawali/rajangyawali.github.io/blob/master/others/files/MSc%20Thesis%20Report.pdf" target="_blank">Read Full Thesis Report</a>
                                    </p>
                                </div>
                            </ul>
                        </div>
                        <div class="border-custom"></div>
                        <div class="card-body">
                            <p><b>Himalaya College of Engineering, Tribhuvan University,</b> Lalitpur, Nepal | 2012 - 2016<br>
                                <i>BE Electronics and Communication Engineering</i></p>
                            <ul>
                                <li>Percentage: <i>82.06%</i></li>
                                <li>Major Subjects: <i>Discrete Mathematics, Artificial Intelligence, Data Mining, Big Data Technologies, Analog and Digital Signal Processing, Computer Networks, Communication Systems</i></li>
                                <li>Minor Project: <b>Smart Irrigation System</b></li>
                                <li>Final Year Project: <b>Brain Controlled Wheelchair</b></li><span class="collapsible">Abstract</span>
                                <div class="collapsible-content">
                                    <p><b>Brain Controlled Wheelchair</b>, an application of <b>Brain Computer Interface
                                        (BCI) </b> uses NeuroSky Mindwave for signal acquisition from the brain. BCI allows direct communication between a computer and brain bypassing the body’s normal neuromuscular pathway. The wheel chair is aimed for
                                        the physically impaired people. Brain Controlled Wheelchair directly measures brain activity associated with the user’s intent and translates the recorded brain activity into corresponding control signals for certain
                                        applications. The signals recorded by the system are processed and classified to recognize the intent of the user. <br>Independent mobility is core to being able to perform activities of daily living by oneself.
                                        Millions of people around the world suffer from mobility impairments and hundreds of thousands of them rely upon powered wheelchairs to get on with their activities of daily living. However, patients are unable
                                        to control the powered wheel chairs using a conventional interface. Hence, a non–invasive brain computer interface (BCI) offer a promising solution to this interaction problem. <br>
                                        <b><i>Keywords:</i></b>Brain Computer Interface, non-invasive, disabled, wheelchair
                                        <br>
                                        <a href="https://github.com/rajangyawali/rajangyawali.github.io/blob/master/others/files/Brain%20Controlled%20Wheelchair%20Project%20Report.pdf" target="_blank">Read Full Project Report</a>
                                    </p>
                                </div>
                            </ul>
                        </div>
                    </div>
                </div>
                <div class="card">
                    <div class="container">
                        <div class="card-title">PUBLICATIONS</div>
                        <div class="card-body">
                            <b>R Gyawali</b>, A Dhakal, L Wang, J Cheng, <i>“CryoSegNet: accurate cryo-EM protein particle picking by integrating the foundational AI image segmentation model and attention-gated U-Net”,</i> Briefings in Bioinformatics 25 (4)<br>
                            <span class="collapsible">Abstract</span>
                            <div class="collapsible-content">
                                <p> Picking protein particles in cryo-electron microscopy (cryo-EM) micrographs is a crucial step in the cryo-EM-based structure determination. However, existing methods trained on a limited amount of cryo-EM data still cannot accurately pick protein particles from noisy cryo-EM images. The general foundational artificial intelligence–based image segmentation model such as Meta’s Segment Anything Model (SAM) cannot segment protein particles well because their training data do not include cryo-EM images. Here, we present a novel approach (CryoSegNet) of integrating an attention-gated U-shape network (U-Net) specially designed and trained for cryo-EM particle picking and the SAM. The U-Net is first trained on a large cryo-EM image dataset and then used to generate input from original cryo-EM images for SAM to make particle pickings. CryoSegNet shows both high precision and recall in segmenting protein particles from cryo-EM micrographs, irrespective of protein type, shape and size. On several independent datasets of various protein types, CryoSegNet outperforms two top machine learning particle pickers crYOLO and Topaz as well as SAM itself. The average resolution of density maps reconstructed from the particles picked by CryoSegNet is 3.33 Å, 7% better than 3.58 Å of Topaz and 14% better than 3.87 Å of crYOLO. It is publicly available at https://github.com/jianlin-cheng/CryoSegNet<br>
                                    <br>
                                    <a href="https://academic.oup.com/bib/article/25/4/bbae282/7690949" target="_blank">Read Full Article</a>
                                </p>
                            </div>

                        </div>
                        <div class="card-body">
                            A Dhakal, <b>R Gyawali</b>, L Wang, J Cheng, <i>“CryoTransformer: a transformer model for picking protein particles from Cryo-EM micrographs”,</i> Bioinformatics 40 (3), btae109<br>
                            <span class="collapsible">Abstract</span>
                            <div class="collapsible-content">
                                <p> Motivation <br>
                                    
                                    Cryo-electron microscopy (cryo-EM) is a powerful technique for determining the structures of large protein complexes. Picking single protein particles from cryo-EM micrographs (images) is a crucial step in reconstructing protein structures from them. However, the widely used template-based particle picking process requires some manual particle picking and is labor-intensive and time-consuming. Though machine learning and artificial intelligence (AI) can potentially automate particle picking, the current AI methods pick particles with low precision or low recall. The erroneously picked particles can severely reduce the quality of reconstructed protein structures, especially for the micrographs with low signal-to-noise ratio.
                                    <br><br>
                                    Results<br>
                                    
                                    To address these shortcomings, we devised CryoTransformer based on transformers, residual networks, and image processing techniques to accurately pick protein particles from cryo-EM micrographs. CryoTransformer was trained and tested on the largest labeled cryo-EM protein particle dataset—CryoPPP. It outperforms the current state-of-the-art machine learning methods of particle picking in terms of the resolution of 3D density maps reconstructed from the picked particles as well as F1-score, and is poised to facilitate the automation of the cryo-EM protein particle picking.
                                    <br><br>
                                    Availability and implementation<br>
                                    
                                    The source code and data for CryoTransformer are openly available at: https://github.com/jianlin-cheng/CryoTransformer.<br>
                                    <br>
                                    <a href="https://academic.oup.com/bioinformatics/article/40/3/btae109/7614090" target="_blank">Read Full Article</a>
                                </p>
                            </div>

                        </div>

                        <div class="card-body">
                            A Dhakal, <b>R Gyawali</b>, L Wang, J Cheng, <i>“A large expert-curated cryo-EM image dataset for machine learning protein particle picking”,</i> Scientific Data 10 (1), 392<br>
                            <span class="collapsible">Abstract</span>
                            <div class="collapsible-content">
                                <p>Cryo-electron microscopy (cryo-EM) is a powerful technique for determining the structures of biological macromolecular complexes. Picking single-protein particles from cryo-EM micrographs is a crucial step in reconstructing protein structures. However, the widely used template-based particle picking process is labor-intensive and time-consuming. Though machine learning and artificial intelligence (AI) based particle picking can potentially automate the process, its development is hindered by lack of large, high-quality labelled training data. To address this bottleneck, we present CryoPPP, a large, diverse, expert-curated cryo-EM image dataset for protein particle picking and analysis. It consists of labelled cryo-EM micrographs (images) of 34 representative protein datasets selected from the Electron Microscopy Public Image Archive (EMPIAR). The dataset is 2.6 terabytes and includes 9,893 high-resolution micrographs with labelled protein particle coordinates. The labelling process was rigorously validated through 2D particle class validation and 3D density map validation with the gold standard. The dataset is expected to greatly facilitate the development of both AI and classical methods for automated cryo-EM protein particle picking.<br>
                                    <br>
                                    <a href="https://www.nature.com/articles/s41597-023-02280-2" target="_blank">Read Full Article</a>
                                </p>
                            </div>

                        </div>

                        <div class="card-body">
                            <b>R Gyawali</b>, D R Pant, <i>“An Approach for the Employee Face Recognition by RPN and Faster R-CNN Techniques”,</i> Proceedings of IOE Graduate Conference, 2019-Summer, Volume 6, May 2019<br>
                            <span class="collapsible">Abstract</span>
                            <div class="collapsible-content">
                                <p>Face recognition is becoming popular in companies, supermarkets, hospitals etc. for security systems, human machine interaction and video surveillances. Employee face recognition is required to differentiate between employees
                                    and non-employees. Face recognition is a challenging task. The traditional machine learning algorithms like Principal Component Analysis, Support Vector Machines, etc. rely on image-based features such as edges and
                                    texture descriptors. In the recent trends, the Convolutional Neural Networks (CNN) and deep learning algorithms have shown greater performance in face recognition. In this article, region proposal network (RPN) is used
                                    to localize region of interests (faces) from the image and Faster R-CNN to output the region proposals’ labels along with their associated bounding box. The proposed system consists of three sections. The first section
                                    uses CNN for features extraction. From these features, the second section generates region proposals using RPN. The third section classifies these region proposals using faster R-CNN and the employee face is recognized.
                                    The accuracy of the model is 96.0% in recognition of Chokepoint employee dataset. The model is further tested with Nepal Telecom employee dataset and shows an accuracy of 95.2%. The performance of the proposed method
                                    is evaluated on these datasets using confusion matrix. Further, visual and comprehensive evaluation using receiver operating characteristics curve for these datasets shows a clear distinction between employees and non-employees.<br>
                                    <br>
                                    <a href="http://conference.ioe.edu.np/publications/ioegc2019-summer/IOEGC-2019-Summer-030.pdf" target="_blank">Read Full Article</a>
                                </p>
                            </div>

                        </div>
                    </div>
                </div>

            </div>
        </div>
    </div>

    <script>
        var coll = document.getElementsByClassName("collapsible");
        var i;

        for (i = 0; i < coll.length; i++) {
            coll[i].addEventListener("click", function() {
                this.classList.toggle("active");
                var content = this.nextElementSibling;
                if (content.style.display === "block") {
                    content.style.display = "none";
                } else {
                    content.style.display = "block";
                }
            });
        }
    </script>
</body>

</html>
